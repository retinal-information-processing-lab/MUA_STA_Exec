{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb1bb432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import spikeinterface.full as si\n",
    "from spikeinterface.sortingcomponents.peak_detection import detect_peaks\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# Configuration graphique\n",
    "matplotlib.use('qt5agg')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b73410aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name):\n",
    "    name = name if name.endswith('.pkl') else name + '.pkl'\n",
    "    path = os.path.normpath(name)\n",
    "    if os.path.dirname(path):\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    name = name if name.endswith('.pkl') else name + '.pkl'\n",
    "    with open(os.path.normpath(name), 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def load_data(input_path, channel_id, nb_channels=256, dtype=\"uint16\", voltage_resolution=0.1042, chunk_size=1000000):\n",
    "    \"\"\"Charge les données par blocs pour permettre l'affichage d'un tqdm.\"\"\"\n",
    "    m = np.memmap(os.path.normpath(input_path), dtype=dtype, mode='r')\n",
    "    nb_samples = m.size // nb_channels\n",
    "    data = np.empty(nb_samples, dtype=float)\n",
    "    \n",
    "    # On itère par blocs d'échantillons\n",
    "    for i in tqdm(range(0, nb_samples, chunk_size), desc=\"Loading Trigger Channel\"):\n",
    "        end = min(i + chunk_size, nb_samples)\n",
    "        # Slicing local au bloc\n",
    "        block = m[i*nb_channels : end*nb_channels]\n",
    "        data[i:end] = block[channel_id::nb_channels].astype(float)\n",
    "    \n",
    "    data = (data + np.iinfo('int16').min) / voltage_resolution\n",
    "    return data, nb_samples\n",
    "\n",
    "def detect_onsets(data, threshold):\n",
    "    \"\"\"Détection vectorisée des fronts montants.\"\"\"\n",
    "    # Cette opération est quasi-instantanée, le tqdm n'est utile que sur le recalage si nécessaire\n",
    "    test = (data[:-1] < threshold) & (data[1:] >= threshold)\n",
    "    indices = np.where(test)[0]\n",
    "    \n",
    "    # Recalage fin\n",
    "    pbar = tqdm(total=5, desc=\"Getting Triggers\", leave=False) # Souvent fini en < 5 itérations\n",
    "    while True:\n",
    "        to_shift = (indices > 0) & (data[indices - 1] < data[indices])\n",
    "        if not np.any(to_shift):\n",
    "            break\n",
    "        indices[to_shift] -= 1\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    return indices\n",
    "\n",
    "def run_sanity_check(triggers, sampling_rate, maximal_jitter=0.25e-3):\n",
    "    if len(triggers) < 2: return np.array([])\n",
    "    inter_triggers = np.diff(triggers)\n",
    "    val, counts = np.unique(inter_triggers, return_counts=True)\n",
    "    mode_val = val[np.argmax(counts)]\n",
    "    errors = np.where(np.abs(inter_triggers - mode_val) >= maximal_jitter * sampling_rate)[0]\n",
    "    if errors.size > 0:\n",
    "        print(f\"⚠️ Erreurs triggers : {len(errors)}\")\n",
    "    else:\n",
    "        print(f\"✅ Triggers OK ({len(triggers)})\")\n",
    "    return triggers[errors].astype('int64')\n",
    "\n",
    "def image_projection(image, setup_id):\n",
    "    if setup_id == 2:\n",
    "        return np.flipud(np.rot90(image))\n",
    "    elif setup_id == 3:\n",
    "        return np.fliplr(image)\n",
    "    return image\n",
    "\n",
    "def checkerboard_from_binary(nb_frames, nb_checks, path, setup_id):\n",
    "    \"\"\"\n",
    "    Version optimisée utilisant la lecture en bloc et le déballage de bits NumPy.\n",
    "    Gagne un facteur >100x en vitesse.\n",
    "    \"\"\"\n",
    "    total_bits = nb_frames * nb_checks * nb_checks\n",
    "    nb_bytes = (total_bits + 7) // 8\n",
    "    \n",
    "    with open(path, mode='rb') as f:\n",
    "        raw_data = np.frombuffer(f.read(nb_bytes), dtype=np.uint8)\n",
    "\n",
    "    all_bits = np.unpackbits(raw_data, bitorder='little')[:total_bits]\n",
    "    \n",
    "    all_frames = all_bits.reshape((nb_frames, nb_checks, nb_checks))\n",
    "    \n",
    "    checkerboard = np.zeros((nb_frames, nb_checks, nb_checks), dtype='uint8')\n",
    "    \n",
    "    for frame in tqdm(range(nb_frames), desc=\"Traitement des frames\"):\n",
    "        image = all_frames[frame].astype(float)\n",
    "        checkerboard[frame] = image_projection(image, setup_id).astype('uint8')\n",
    "        \n",
    "    return checkerboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80b38f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_sequence(cell_spikes, triggers, nb_repeats, stim_frequency, nb_frames_by_sequence, sequence_portion=(0.5, 1)):\n",
    "    # 1. Pre-calculate indices and dimensions\n",
    "    f0, f1 = sequence_portion\n",
    "    nb_frames_portion = int((f1 - f0) * nb_frames_by_sequence)\n",
    "    \n",
    "    # Pre-calculate all start and end triggers for all repeats at once\n",
    "    start_indices = np.arange(nb_repeats) * nb_frames_by_sequence + int(f0 * nb_frames_by_sequence)\n",
    "    end_indices = np.arange(nb_repeats) * nb_frames_by_sequence + int(f1 * nb_frames_by_sequence)\n",
    "    \n",
    "    t_starts = triggers[start_indices]\n",
    "    t_ends = triggers[end_indices]\n",
    "    \n",
    "    spike_trains = []\n",
    "    spikes_counts = np.zeros((nb_repeats, nb_frames_portion))\n",
    "\n",
    "    # 2. Use binary search (searchsorted) to find spikes within the range [min(t_starts), max(t_ends)]\n",
    "    # This avoids scanning spikes that are outside the entire experiment portion\n",
    "    relevant_indices = np.searchsorted(cell_spikes, [t_starts.min(), t_ends.max()])\n",
    "    relevant_spikes = cell_spikes[relevant_indices[0]:relevant_indices[1]]\n",
    "\n",
    "    # 3. Optimized Loop\n",
    "    for i in range(nb_repeats):\n",
    "        ts = t_starts[i]\n",
    "        te = t_ends[i]\n",
    "        \n",
    "        # Binary search is much faster than boolean masking for sorted data\n",
    "        idx_s, idx_e = np.searchsorted(relevant_spikes, [ts, te])\n",
    "        spike_seq = relevant_spikes[idx_s:idx_e] - ts\n",
    "        \n",
    "        spike_trains.append(spike_seq)\n",
    "\n",
    "        # Vectorized histogram (histogram is still good, but we limit the data it sees)\n",
    "        counts, _ = np.histogram(spike_seq, bins=nb_frames_portion, range=(0, te - ts))\n",
    "        spikes_counts[i, :] = counts\n",
    "\n",
    "    return {\n",
    "        \"spike_trains\": spike_trains,\n",
    "        \"counted_spikes\": spikes_counts,\n",
    "        \"psth\": spikes_counts.sum(axis=0) / nb_repeats * stim_frequency\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_3D_sta(data, checkerboard, nb_frames_by_sequence, temporal_dimension):\n",
    "    # 1. Flatten the spikes into a 1D array across all sequences/frames\n",
    "    # We only care about the frames where spikes could actually trigger a window\n",
    "    nb_frames_half = int(nb_frames_by_sequence / 2)\n",
    "    spikes = data[\"counted_spikes\"][:, temporal_dimension:nb_frames_half].flatten()\n",
    "    total_spikes = np.sum(spikes)\n",
    "    \n",
    "    if total_spikes == 0:\n",
    "        return np.zeros((temporal_dimension, checkerboard.shape[1], checkerboard.shape[2]))\n",
    "\n",
    "    # 2. Identify indices where spikes occurred to avoid multiplying by zero\n",
    "    spike_indices = np.where(spikes > 0)[0]\n",
    "    weights = spikes[spike_indices]\n",
    "    \n",
    "    # 3. Vectorized window extraction\n",
    "    # We map the flattened spike index back to the checkerboard index\n",
    "    # idx_start = (seq * nb_frames_half) + frame - temporal_dimension\n",
    "    # Since 'spikes' is already sliced from temporal_dimension, we adjust:\n",
    "    sta = np.zeros((temporal_dimension, checkerboard.shape[1], checkerboard.shape[2]))\n",
    "    \n",
    "    for i, w in zip(spike_indices, weights):\n",
    "        # Calculate the start/end in the checkerboard for this specific spike\n",
    "        # The offset accounts for the 'temporal_dimension' skip in the spike data\n",
    "        seq_idx = i // (nb_frames_half - temporal_dimension)\n",
    "        frame_in_seq = i % (nb_frames_half - temporal_dimension) + temporal_dimension\n",
    "        \n",
    "        start = seq_idx * nb_frames_half + frame_in_seq - temporal_dimension\n",
    "        end = start + temporal_dimension\n",
    "        sta += w * checkerboard[start:end, :, :]\n",
    "\n",
    "    # 4. Normalization\n",
    "    sta /= total_spikes\n",
    "    sta -= np.mean(sta)\n",
    "    max_val = np.max(np.abs(sta))\n",
    "    if max_val > 0:\n",
    "        sta /= max_val\n",
    "        \n",
    "    return sta\n",
    "def get_temporal_spatial_sta(sta_3D):\n",
    "    # Use unravel_index on the absolute max to find the \"peak\" pixel and time\n",
    "    idx_max = np.argmax(np.abs(sta_3D))\n",
    "    best_t, best_x, best_y = np.unravel_index(idx_max, sta_3D.shape)\n",
    "    \n",
    "    # Extract slices\n",
    "    sta_temporal = sta_3D[:, best_x, best_y]\n",
    "    sta_spatial = sta_3D[best_t, :, :]\n",
    "    \n",
    "    # Vectorized normalization\n",
    "    max_spatial = np.max(np.abs(sta_spatial))\n",
    "    if max_spatial > 0:\n",
    "        sta_spatial = sta_spatial / max_spatial\n",
    "        \n",
    "    return sta_temporal, sta_spatial, (best_t, best_x, best_y)\n",
    "\n",
    "\n",
    "\n",
    "def process_single_electrode(args):\n",
    "    \"\"\"Function to process a single electrode - must be top-level for pickling.\"\"\"\n",
    "    electrode, mapping_info, spike_train, triggers, params = args\n",
    "    row, col = mapping_info\n",
    "    \n",
    "    # Extract params for clarity\n",
    "    nb_repeats = params['nb_repeats']\n",
    "    stim_freq = params['stim_freq']\n",
    "    nb_frames = params['nb_frames']\n",
    "    temp_dim = params['temp_dim']\n",
    "    checkerboard = params['checkerboard']\n",
    "\n",
    "    # 1. Compute Raster Data\n",
    "    res_r = extract_from_sequence(spike_train, triggers, nb_repeats, stim_freq, nb_frames, (0.5, 1))\n",
    "    \n",
    "    # 2. Compute STA Data\n",
    "    res_s = extract_from_sequence(spike_train, triggers, nb_repeats, stim_freq, nb_frames, (0, 0.5))\n",
    "    sta_3d = compute_3D_sta(res_s, checkerboard, nb_frames, temp_dim)\n",
    "    _, sta_spat, _ = get_temporal_spatial_sta(sta_3d)\n",
    "\n",
    "    return electrode, {\n",
    "        'raster_spikes': res_r[\"spike_trains\"],\n",
    "        'sta_spatial': sta_spat\n",
    "    }\n",
    "\n",
    "def plot_stitched_sta(data_source, mapping, grid_size=16, padding=3):\n",
    "    \"\"\"\n",
    "    Stitches individual 2D STAs into a single large 16x16 grid for fast rendering.\n",
    "    \"\"\"\n",
    "    # 1. Handle data format (list of tuples from parallel vs. dictionary)\n",
    "    if isinstance(data_source, list):\n",
    "        data_dict = dict(data_source)\n",
    "    else:\n",
    "        data_dict = data_source\n",
    "\n",
    "    if not data_dict:\n",
    "        print(\"Error: No processed data found.\")\n",
    "        return\n",
    "\n",
    "    # 2. Get dimensions from the first available electrode\n",
    "    first_elec_id = next(iter(data_dict))\n",
    "    h, w = data_dict[first_elec_id]['sta_spatial'].shape\n",
    "\n",
    "    # 3. Create a giant empty canvas initialized with NaNs (for white padding)\n",
    "    canvas_h = grid_size * h + (grid_size - 1) * padding\n",
    "    canvas_w = grid_size * w + (grid_size - 1) * padding\n",
    "    full_canvas = np.full((canvas_h, canvas_w), np.nan) \n",
    "\n",
    "    # 4. Fill the canvas\n",
    "    for electrode, (row, col) in mapping.items():\n",
    "        if electrode not in data_dict:\n",
    "            continue\n",
    "            \n",
    "        sta = data_dict[electrode]['sta_spatial'].copy()\n",
    "        \n",
    "        # Local normalization for visibility\n",
    "        vmax = np.max(np.abs(sta))\n",
    "        if vmax > 0:\n",
    "            sta /= vmax\n",
    "        \n",
    "        # Calculate pixel coordinates\n",
    "        y_start = row * (h + padding)\n",
    "        x_start = col * (w + padding)\n",
    "        \n",
    "        full_canvas[y_start : y_start + h, x_start : x_start + w] = sta\n",
    "\n",
    "    # 5. Rendering\n",
    "    plt.figure(figsize=(14, 14))\n",
    "    \n",
    "    # Configure colormap to show NaNs as white\n",
    "    current_cmap = plt.cm.get_cmap('bwr').copy()\n",
    "    current_cmap.set_bad(color='white') \n",
    "\n",
    "    plt.imshow(full_canvas, cmap=current_cmap, vmin=-1, vmax=1, interpolation='nearest')\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Stitched STA Grid ({grid_size}x{grid_size})\", fontsize=16, pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60ed53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paramètres d'acquisition ---\n",
    "SAMPLING_RATE = 20000\n",
    "TOTAL_CHANNELS = 256\n",
    "TRIGGER_CHANNEL = 126\n",
    "DATA_TYPE = 'uint16'\n",
    "\n",
    "# --- Choix du Setup ---\n",
    "SETUP = 3  # 1 pour MEA1, 2 pour MEA2, 3 pour Opto\n",
    "\n",
    "if SETUP == 1:\n",
    "    DMD_POLARITY = 1\n",
    "    PIXEL_SIZE = 2.3\n",
    "    TRIGGER_THRESHOLD = 150e+3\n",
    "elif SETUP == 2:\n",
    "    DMD_POLARITY = 1\n",
    "    PIXEL_SIZE = 3.5\n",
    "    TRIGGER_THRESHOLD = 150e+3\n",
    "elif SETUP == 3:\n",
    "    DMD_POLARITY = -1\n",
    "    PIXEL_SIZE = 2.8\n",
    "    TRIGGER_THRESHOLD = 170e+3\n",
    "\n",
    "# --- Paramètres Stimulus & Analyse ---\n",
    "NB_CHECKS = 40\n",
    "NB_FRAMES_SEQ = 1200\n",
    "TEMPORAL_DIM = 30\n",
    "PLOT_RASTER = True  # Équivalent au input \"y/n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9db45c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected File : /home/guiglaz/Documents/MultiunitFromRaw/01_Checkerboard_30Hz_16px_40sq_30ND50%.raw\n"
     ]
    }
   ],
   "source": [
    "# Sélection fichier\n",
    "root = tk.Tk(); root.withdraw()\n",
    "raw_path = filedialog.askopenfilename(title='Select a Checkerboard RAW file...')\n",
    "if not raw_path: \n",
    "    print('File not Found')\n",
    "    exit()\n",
    "else:\n",
    "    print(f\"Selected File : {raw_path}\")\n",
    "mapping = load_obj('./electrodes_mapping_MEA_MCS_256.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9d8ce2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction des spikes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e16aeb9b22c4f52bacc5ba52c151ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "detect peaks using by_channel:   0%|          | 0/3703 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Traitement Spikes\n",
    "print(\"Extraction des spikes...\")\n",
    "rec = si.read_binary(raw_path, sampling_frequency=SAMPLING_RATE, num_channels=TOTAL_CHANNELS, dtype=DATA_TYPE)\n",
    "\n",
    "# Conversion spécifique SI pour passer en signé proprement\n",
    "# rec = si.unsigned_to_signed(rec)\n",
    "\n",
    "rec_filt = si.common_reference(si.bandpass_filter(rec))\n",
    "\n",
    "\n",
    "peaks = detect_peaks(rec_filt, method=\"by_channel\", peak_sign=\"neg\", detect_threshold=6, n_jobs=10, progress_bar=True)\n",
    "spike_trains_mua = defaultdict(list)\n",
    "for p in peaks: spike_trains_mua[p[1]].append(p[0] / SAMPLING_RATE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66c2317f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture triggers...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42de536253d94651942e0238745c9cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading Trigger Channel:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting Triggers:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Triggers OK (110462)\n",
      "Detected Stimulus Frequency: 30 Hz\n",
      "Number of repeats: 92\n"
     ]
    }
   ],
   "source": [
    "# 2. Triggers\n",
    "print(\"Lecture triggers...\")\n",
    "trig_raw, _ = load_data(raw_path, channel_id=TRIGGER_CHANNEL)\n",
    "trig_idx = detect_onsets(trig_raw, TRIGGER_THRESHOLD)\n",
    "run_sanity_check(trig_idx, SAMPLING_RATE)\n",
    "triggers = trig_idx / SAMPLING_RATE\n",
    "nb_repeats = len(triggers) // NB_FRAMES_SEQ\n",
    "\n",
    "# --- Compute STIM_FREQ dynamically ---\n",
    "# Calculate the mean time between consecutive frames (triggers)\n",
    "# frequency = 1 / mean_inter_trigger_interval\n",
    "avg_dt = np.mean(np.diff(triggers))\n",
    "STIM_FREQ = int(round(1.0 / avg_dt))\n",
    "\n",
    "print(f\"Detected Stimulus Frequency: {STIM_FREQ} Hz\")\n",
    "print(f\"Number of repeats: {nb_repeats}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94150057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement stimulus...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65244221694c457e9cf7fc0c417af8b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Traitement des frames:   0%|          | 0/55200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Stimulus\n",
    "print(\"Chargement stimulus...\")\n",
    "stim_path = \"./binarysource1000Mbits\"\n",
    "checkerboard = checkerboard_from_binary(nb_repeats * (NB_FRAMES_SEQ // 2), NB_CHECKS, stim_path, SETUP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b77bb756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154a70ddc2fa491d9ea5ae45bb1f2b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parallel Analysis:   0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Prepare shared parameters\n",
    "params = {\n",
    "    'nb_repeats': nb_repeats,\n",
    "    'stim_freq': STIM_FREQ,\n",
    "    'nb_frames': NB_FRAMES_SEQ,\n",
    "    'temp_dim': TEMPORAL_DIM,\n",
    "    'checkerboard': checkerboard # Note: Large arrays can be slow to pass between processes\n",
    "}\n",
    "\n",
    "# 2. Filter tasks\n",
    "tasks = [\n",
    "    (elec, mapping[elec], np.array(spike_trains_mua[elec]), triggers, params)\n",
    "    for elec in mapping.keys()\n",
    "    if elec not in [127, 128, 255, 256] and elec in spike_trains_mua\n",
    "]\n",
    "\n",
    "processed_data = {}\n",
    "\n",
    "# 3. Run in Parallel\n",
    "# Adjust max_workers to the number of physical cores you want to use (e.g., 4, 8, or None for all)\n",
    "with ProcessPoolExecutor(max_workers=10) as executor:\n",
    "    results = list(tqdm(executor.map(process_single_electrode, tasks), \n",
    "                        total=len(tasks), \n",
    "                        desc=\"Parallel Analysis\"))\n",
    "\n",
    "# 4. Convert list of tuples back to dictionary\n",
    "processed_data = dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "820d5963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dccd59293e144250a4c1cf527f1b40cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if PLOT_RASTER :\n",
    "    fig_r, axs_r = plt.subplots(16, 16, figsize=(15, 15))\n",
    "\n",
    "    for electrode, (row, col) in tqdm(mapping.items()):\n",
    "        ax_r = axs_r[row, col]\n",
    "\n",
    "        # Check if we have data for this electrode\n",
    "        if electrode not in processed_data:\n",
    "            ax_r.axis('off')\n",
    "            continue\n",
    "\n",
    "        data = processed_data[electrode]\n",
    "\n",
    "        # --- Plot Raster ---\n",
    "        ax_r.eventplot(data['raster_spikes'], linewidths=0.1, color='black')\n",
    "        ax_r.set_xticks([]); ax_r.set_yticks([])\n",
    "\n",
    "    plt.show(block = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a979f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba247cf34d3f405c9f282fd6b49feb79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Plotting Rasters:   0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if PLOT_RASTER:\n",
    "    # On utilise une résolution de DPI raisonnable pour ne pas ramer à l'affichage\n",
    "    fig_r, axs_r = plt.subplots(16, 16, figsize=(16, 16))\n",
    "    \n",
    "    data_dict = dict(processed_data) if isinstance(processed_data, list) else processed_data\n",
    "    \n",
    "    for electrode, (row, col) in tqdm(mapping.items(), desc=\"Plotting Rasters\"):\n",
    "        ax_r = axs_r[row, col]\n",
    "    \n",
    "        ax_r.set_xticks([])\n",
    "        ax_r.set_yticks([])\n",
    "        for spine in ax_r.spines.values():\n",
    "            spine.set_visible(False)\n",
    "    \n",
    "        if electrode not in data_dict:\n",
    "            # On laisse les électrodes vides en gris très clair pour voir la grille\n",
    "            ax_r.set_facecolor('#f9f9f9') \n",
    "            continue\n",
    "        data = data_dict[electrode]\n",
    "        ax_r.eventplot(data['raster_spikes'], \n",
    "                       linewidths=0.1, \n",
    "                       color='black', \n",
    "                       rasterized=True) \n",
    "    \n",
    "    \n",
    "    # 4. Ajustement manuel (beaucoup plus rapide que tight_layout)\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1, left=0.01, right=0.99, bottom=0.01, top=0.99)\n",
    "    \n",
    "    plt.show(block = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "455c55bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stitched_sta(processed_data, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86177b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected File : /home/guiglaz/Documents/MultiunitFromRaw/01_Checkerboard_30Hz_16px_40sq_30ND50%.raw\n",
      "Lecture triggers...\n",
      "Loading Trigger Channel: 100%|██████████████████| 75/75 [00:01<00:00, 53.08it/s]\n",
      "✅ Triggers OK (110462)                                                          \n",
      "Detected Stimulus Frequency: 30 Hz\n",
      "Number of repeats: 92\n",
      "Extraction des spikes...\n",
      "detect peaks using by_channel: 100%|████████| 3703/3703 [01:11<00:00, 51.96it/s]\n",
      "Chargement stimulus...\n",
      "Traitement des frames: 100%|██████████| 55200/55200 [00:00<00:00, 402962.94it/s]\n",
      "Parallel Analysis: 100%|██████████████████████| 252/252 [00:24<00:00, 10.09it/s]\n",
      "100%|█████████████████████████████████████████| 256/256 [00:12<00:00, 21.04it/s]\n",
      "Press any key to close...^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guiglaz/Documents/MultiunitFromRaw/STA_MU_Exec.py\", line 415, in <module>\n",
      "    input('Press any key to close...')\n",
      "KeyboardInterrupt\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python STA_MU_Exec.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
