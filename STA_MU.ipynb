{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb1bb432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import spikeinterface.full as si\n",
    "from spikeinterface.sortingcomponents.peak_detection import detect_peaks\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# Configuration graphique\n",
    "matplotlib.use('qt5agg')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b73410aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name):\n",
    "    name = name if name.endswith('.pkl') else name + '.pkl'\n",
    "    path = os.path.normpath(name)\n",
    "    if os.path.dirname(path):\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    name = name if name.endswith('.pkl') else name + '.pkl'\n",
    "    with open(os.path.normpath(name), 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def load_data(input_path, channel_id, nb_channels=256, dtype=\"uint16\", voltage_resolution=0.1042, chunk_size=1000000):\n",
    "    \"\"\"Charge les données par blocs pour permettre l'affichage d'un tqdm.\"\"\"\n",
    "    m = np.memmap(os.path.normpath(input_path), dtype=dtype, mode='r')\n",
    "    nb_samples = m.size // nb_channels\n",
    "    data = np.empty(nb_samples, dtype=float)\n",
    "    \n",
    "    # On itère par blocs d'échantillons\n",
    "    for i in tqdm(range(0, nb_samples, chunk_size), desc=\"Loading Trigger Channel\"):\n",
    "        end = min(i + chunk_size, nb_samples)\n",
    "        # Slicing local au bloc\n",
    "        block = m[i*nb_channels : end*nb_channels]\n",
    "        data[i:end] = block[channel_id::nb_channels].astype(float)\n",
    "    \n",
    "    data = (data + np.iinfo('int16').min) / voltage_resolution\n",
    "    return data, nb_samples\n",
    "\n",
    "def detect_onsets(data, threshold):\n",
    "    \"\"\"Détection vectorisée des fronts montants.\"\"\"\n",
    "    # Cette opération est quasi-instantanée, le tqdm n'est utile que sur le recalage si nécessaire\n",
    "    test = (data[:-1] < threshold) & (data[1:] >= threshold)\n",
    "    indices = np.where(test)[0]\n",
    "    \n",
    "    # Recalage fin\n",
    "    pbar = tqdm(total=5, desc=\"Getting Triggers\", leave=False) # Souvent fini en < 5 itérations\n",
    "    while True:\n",
    "        to_shift = (indices > 0) & (data[indices - 1] < data[indices])\n",
    "        if not np.any(to_shift):\n",
    "            break\n",
    "        indices[to_shift] -= 1\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    return indices\n",
    "\n",
    "def run_sanity_check(triggers, sampling_rate, maximal_jitter=0.25e-3):\n",
    "    if len(triggers) < 2: return np.array([])\n",
    "    inter_triggers = np.diff(triggers)\n",
    "    val, counts = np.unique(inter_triggers, return_counts=True)\n",
    "    mode_val = val[np.argmax(counts)]\n",
    "    errors = np.where(np.abs(inter_triggers - mode_val) >= maximal_jitter * sampling_rate)[0]\n",
    "    if errors.size > 0:\n",
    "        print(f\"⚠️ Erreurs triggers : {len(errors)}\")\n",
    "    else:\n",
    "        print(f\"✅ Triggers OK ({len(triggers)})\")\n",
    "    return triggers[errors].astype('int64')\n",
    "\n",
    "def image_projection(image, setup_id):\n",
    "    if setup_id == 2:\n",
    "        return np.flipud(np.rot90(image))\n",
    "    elif setup_id == 3:\n",
    "        return np.fliplr(image)\n",
    "    return image\n",
    "\n",
    "def checkerboard_from_binary(nb_frames, nb_checks, path, setup_id):\n",
    "    \"\"\"\n",
    "    Version optimisée utilisant la lecture en bloc et le déballage de bits NumPy.\n",
    "    Gagne un facteur >100x en vitesse.\n",
    "    \"\"\"\n",
    "    total_bits = nb_frames * nb_checks * nb_checks\n",
    "    nb_bytes = (total_bits + 7) // 8\n",
    "    \n",
    "    with open(path, mode='rb') as f:\n",
    "        raw_data = np.frombuffer(f.read(nb_bytes), dtype=np.uint8)\n",
    "\n",
    "    all_bits = np.unpackbits(raw_data, bitorder='little')[:total_bits]\n",
    "    \n",
    "    all_frames = all_bits.reshape((nb_frames, nb_checks, nb_checks))\n",
    "    \n",
    "    checkerboard = np.zeros((nb_frames, nb_checks, nb_checks), dtype='uint8')\n",
    "    \n",
    "    for frame in tqdm(range(nb_frames), desc=\"Traitement des frames\"):\n",
    "        image = all_frames[frame].astype(float)\n",
    "        checkerboard[frame] = image_projection(image, setup_id).astype('uint8')\n",
    "        \n",
    "    return checkerboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80b38f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_sequence(cell_spikes, triggers, nb_repeats, stim_frequency, nb_frames_by_sequence, sequence_portion=(0.5, 1)):\n",
    "    # 1. Pre-calculate indices and dimensions\n",
    "    f0, f1 = sequence_portion\n",
    "    nb_frames_portion = int((f1 - f0) * nb_frames_by_sequence)\n",
    "    \n",
    "    # Pre-calculate all start and end triggers for all repeats at once\n",
    "    start_indices = np.arange(nb_repeats) * nb_frames_by_sequence + int(f0 * nb_frames_by_sequence)\n",
    "    end_indices = np.arange(nb_repeats) * nb_frames_by_sequence + int(f1 * nb_frames_by_sequence)\n",
    "    \n",
    "    t_starts = triggers[start_indices]\n",
    "    t_ends = triggers[end_indices]\n",
    "    \n",
    "    spike_trains = []\n",
    "    spikes_counts = np.zeros((nb_repeats, nb_frames_portion))\n",
    "\n",
    "    # 2. Use binary search (searchsorted) to find spikes within the range [min(t_starts), max(t_ends)]\n",
    "    # This avoids scanning spikes that are outside the entire experiment portion\n",
    "    relevant_indices = np.searchsorted(cell_spikes, [t_starts.min(), t_ends.max()])\n",
    "    relevant_spikes = cell_spikes[relevant_indices[0]:relevant_indices[1]]\n",
    "\n",
    "    # 3. Optimized Loop\n",
    "    for i in range(nb_repeats):\n",
    "        ts = t_starts[i]\n",
    "        te = t_ends[i]\n",
    "        \n",
    "        # Binary search is much faster than boolean masking for sorted data\n",
    "        idx_s, idx_e = np.searchsorted(relevant_spikes, [ts, te])\n",
    "        spike_seq = relevant_spikes[idx_s:idx_e] - ts\n",
    "        \n",
    "        spike_trains.append(spike_seq)\n",
    "\n",
    "        # Vectorized histogram (histogram is still good, but we limit the data it sees)\n",
    "        counts, _ = np.histogram(spike_seq, bins=nb_frames_portion, range=(0, te - ts))\n",
    "        spikes_counts[i, :] = counts\n",
    "\n",
    "    return {\n",
    "        \"spike_trains\": spike_trains,\n",
    "        \"counted_spikes\": spikes_counts,\n",
    "        \"psth\": spikes_counts.sum(axis=0) / nb_repeats * stim_frequency\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_3D_sta(data, checkerboard, nb_frames_by_sequence, temporal_dimension):\n",
    "    # 1. Flatten the spikes into a 1D array across all sequences/frames\n",
    "    # We only care about the frames where spikes could actually trigger a window\n",
    "    nb_frames_half = int(nb_frames_by_sequence / 2)\n",
    "    spikes = data[\"counted_spikes\"][:, temporal_dimension:nb_frames_half].flatten()\n",
    "    total_spikes = np.sum(spikes)\n",
    "    \n",
    "    if total_spikes == 0:\n",
    "        return np.zeros((temporal_dimension, checkerboard.shape[1], checkerboard.shape[2]))\n",
    "\n",
    "    # 2. Identify indices where spikes occurred to avoid multiplying by zero\n",
    "    spike_indices = np.where(spikes > 0)[0]\n",
    "    weights = spikes[spike_indices]\n",
    "    \n",
    "    # 3. Vectorized window extraction\n",
    "    # We map the flattened spike index back to the checkerboard index\n",
    "    # idx_start = (seq * nb_frames_half) + frame - temporal_dimension\n",
    "    # Since 'spikes' is already sliced from temporal_dimension, we adjust:\n",
    "    sta = np.zeros((temporal_dimension, checkerboard.shape[1], checkerboard.shape[2]))\n",
    "    \n",
    "    for i, w in zip(spike_indices, weights):\n",
    "        # Calculate the start/end in the checkerboard for this specific spike\n",
    "        # The offset accounts for the 'temporal_dimension' skip in the spike data\n",
    "        seq_idx = i // (nb_frames_half - temporal_dimension)\n",
    "        frame_in_seq = i % (nb_frames_half - temporal_dimension) + temporal_dimension\n",
    "        \n",
    "        start = seq_idx * nb_frames_half + frame_in_seq - temporal_dimension\n",
    "        end = start + temporal_dimension\n",
    "        sta += w * checkerboard[start:end, :, :]\n",
    "\n",
    "    # 4. Normalization\n",
    "    sta /= total_spikes\n",
    "    sta -= np.mean(sta)\n",
    "    max_val = np.max(np.abs(sta))\n",
    "    if max_val > 0:\n",
    "        sta /= max_val\n",
    "        \n",
    "    return sta\n",
    "def get_temporal_spatial_sta(sta_3D):\n",
    "    # Use unravel_index on the absolute max to find the \"peak\" pixel and time\n",
    "    idx_max = np.argmax(np.abs(sta_3D))\n",
    "    best_t, best_x, best_y = np.unravel_index(idx_max, sta_3D.shape)\n",
    "    \n",
    "    # Extract slices\n",
    "    sta_temporal = sta_3D[:, best_x, best_y]\n",
    "    sta_spatial = sta_3D[best_t, :, :]\n",
    "    \n",
    "    # Vectorized normalization\n",
    "    max_spatial = np.max(np.abs(sta_spatial))\n",
    "    if max_spatial > 0:\n",
    "        sta_spatial = sta_spatial / max_spatial\n",
    "        \n",
    "    return sta_temporal, sta_spatial, (best_t, best_x, best_y)\n",
    "\n",
    "\n",
    "\n",
    "def process_single_electrode(args):\n",
    "    \"\"\"Function to process a single electrode - must be top-level for pickling.\"\"\"\n",
    "    electrode, mapping_info, spike_train, triggers, params = args\n",
    "    row, col = mapping_info\n",
    "    \n",
    "    # Extract params for clarity\n",
    "    nb_repeats = params['nb_repeats']\n",
    "    stim_freq = params['stim_freq']\n",
    "    nb_frames = params['nb_frames']\n",
    "    temp_dim = params['temp_dim']\n",
    "    checkerboard = params['checkerboard']\n",
    "\n",
    "    # 1. Compute Raster Data\n",
    "    res_r = extract_from_sequence(spike_train, triggers, nb_repeats, stim_freq, nb_frames, (0.5, 1))\n",
    "    \n",
    "    # 2. Compute STA Data\n",
    "    res_s = extract_from_sequence(spike_train, triggers, nb_repeats, stim_freq, nb_frames, (0, 0.5))\n",
    "    sta_3d = compute_3D_sta(res_s, checkerboard, nb_frames, temp_dim)\n",
    "    _, sta_spat, _ = get_temporal_spatial_sta(sta_3d)\n",
    "\n",
    "    return electrode, {\n",
    "        'raster_spikes': res_r[\"spike_trains\"],\n",
    "        'sta_spatial': sta_spat\n",
    "    }\n",
    "\n",
    "def plot_stitched_sta(data_source, mapping, grid_size=16, padding=3):\n",
    "    \"\"\"\n",
    "    Stitches individual 2D STAs into a single large 16x16 grid for fast rendering.\n",
    "    \"\"\"\n",
    "    # 1. Handle data format (list of tuples from parallel vs. dictionary)\n",
    "    if isinstance(data_source, list):\n",
    "        data_dict = dict(data_source)\n",
    "    else:\n",
    "        data_dict = data_source\n",
    "\n",
    "    if not data_dict:\n",
    "        print(\"Error: No processed data found.\")\n",
    "        return\n",
    "\n",
    "    # 2. Get dimensions from the first available electrode\n",
    "    first_elec_id = next(iter(data_dict))\n",
    "    h, w = data_dict[first_elec_id]['sta_spatial'].shape\n",
    "\n",
    "    # 3. Create a giant empty canvas initialized with NaNs (for white padding)\n",
    "    canvas_h = grid_size * h + (grid_size - 1) * padding\n",
    "    canvas_w = grid_size * w + (grid_size - 1) * padding\n",
    "    full_canvas = np.full((canvas_h, canvas_w), np.nan) \n",
    "\n",
    "    # 4. Fill the canvas\n",
    "    for electrode, (row, col) in mapping.items():\n",
    "        if electrode not in data_dict:\n",
    "            continue\n",
    "            \n",
    "        sta = data_dict[electrode]['sta_spatial'].copy()\n",
    "        \n",
    "        # Local normalization for visibility\n",
    "        vmax = np.max(np.abs(sta))\n",
    "        if vmax > 0:\n",
    "            sta /= vmax\n",
    "        \n",
    "        # Calculate pixel coordinates\n",
    "        y_start = row * (h + padding)\n",
    "        x_start = col * (w + padding)\n",
    "        \n",
    "        full_canvas[y_start : y_start + h, x_start : x_start + w] = sta\n",
    "\n",
    "    # 5. Rendering\n",
    "    plt.figure(figsize=(14, 14))\n",
    "    \n",
    "    # Configure colormap to show NaNs as white\n",
    "    current_cmap = plt.cm.get_cmap('bwr').copy()\n",
    "    current_cmap.set_bad(color='white') \n",
    "\n",
    "    plt.imshow(full_canvas, cmap=current_cmap, vmin=-1, vmax=1, interpolation='nearest')\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Stitched STA Grid ({grid_size}x{grid_size})\", fontsize=16, pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c60ed53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paramètres d'acquisition ---\n",
    "SAMPLING_RATE = 20000\n",
    "TOTAL_CHANNELS = 256\n",
    "TRIGGER_CHANNEL = 126\n",
    "DATA_TYPE = 'uint16'\n",
    "\n",
    "# --- Choix du Setup ---\n",
    "SETUP = 3  # 1 pour MEA1, 2 pour MEA2, 3 pour Opto\n",
    "\n",
    "if SETUP == 1:\n",
    "    DMD_POLARITY = 1\n",
    "    PIXEL_SIZE = 2.3\n",
    "    TRIGGER_THRESHOLD = 150e+3\n",
    "elif SETUP == 2:\n",
    "    DMD_POLARITY = 1\n",
    "    PIXEL_SIZE = 3.5\n",
    "    TRIGGER_THRESHOLD = 150e+3\n",
    "elif SETUP == 3:\n",
    "    DMD_POLARITY = -1\n",
    "    PIXEL_SIZE = 2.8\n",
    "    TRIGGER_THRESHOLD = 170e+3\n",
    "\n",
    "# --- Paramètres Stimulus & Analyse ---\n",
    "NB_CHECKS = 40\n",
    "NB_FRAMES_SEQ = 1200\n",
    "TEMPORAL_DIM = 30\n",
    "PLOT_RASTER = True  # Équivalent au input \"y/n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9db45c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected File : /mnt/Extra/PulsatingGrating/20250604_PulsingGrating/RAW_Files/01_ShiftingWhiteNoise_30Hz_30ND50%.raw\n"
     ]
    }
   ],
   "source": [
    "# Sélection fichier\n",
    "root = tk.Tk(); root.withdraw()\n",
    "raw_path = filedialog.askopenfilename(title='Select a Checkerboard RAW file...')\n",
    "if not raw_path: \n",
    "    print('File not Found')\n",
    "    exit()\n",
    "else:\n",
    "    print(f\"Selected File : {raw_path}\")\n",
    "mapping = load_obj('./electrodes_mapping_MEA_MCS_256.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9d8ce2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction des spikes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54935804e82a4398960eb28f15f3f035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "detect peaks using by_channel:   0%|          | 0/1846 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Traitement Spikes\n",
    "print(\"Extraction des spikes...\")\n",
    "rec = si.read_binary(raw_path, sampling_frequency=SAMPLING_RATE, num_channels=TOTAL_CHANNELS, dtype=DATA_TYPE)\n",
    "\n",
    "# Conversion spécifique SI pour passer en signé proprement\n",
    "# rec = si.unsigned_to_signed(rec)\n",
    "\n",
    "rec_filt = si.common_reference(si.bandpass_filter(rec))\n",
    "\n",
    "\n",
    "peaks = detect_peaks(rec_filt, method=\"by_channel\", peak_sign=\"neg\", detect_threshold=6, n_jobs=10, progress_bar=True)\n",
    "spike_trains_mua = defaultdict(list)\n",
    "for p in peaks: spike_trains_mua[p[1]].append(p[0] / SAMPLING_RATE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66c2317f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture triggers...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bf0c5de236499d9fa81a40652ad654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading Trigger Channel:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting Triggers:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Triggers OK (54000)\n",
      "Detected Stimulus Frequency: 30 Hz\n",
      "Number of repeats: 45\n"
     ]
    }
   ],
   "source": [
    "# 2. Triggers\n",
    "print(\"Lecture triggers...\")\n",
    "trig_raw, _ = load_data(raw_path, channel_id=TRIGGER_CHANNEL)\n",
    "trig_idx = detect_onsets(trig_raw, TRIGGER_THRESHOLD)\n",
    "run_sanity_check(trig_idx, SAMPLING_RATE)\n",
    "triggers = trig_idx / SAMPLING_RATE\n",
    "nb_repeats = len(triggers) // NB_FRAMES_SEQ\n",
    "\n",
    "# --- Compute STIM_FREQ dynamically ---\n",
    "# Calculate the mean time between consecutive frames (triggers)\n",
    "# frequency = 1 / mean_inter_trigger_interval\n",
    "avg_dt = np.mean(np.diff(triggers))\n",
    "STIM_FREQ = int(round(1.0 / avg_dt))\n",
    "\n",
    "print(f\"Detected Stimulus Frequency: {STIM_FREQ} Hz\")\n",
    "print(f\"Number of repeats: {nb_repeats}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94150057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement stimulus...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65244221694c457e9cf7fc0c417af8b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Traitement des frames:   0%|          | 0/55200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Stimulus\n",
    "print(\"Chargement stimulus...\")\n",
    "stim_path = \"./binarysource1000Mbits\"\n",
    "checkerboard = checkerboard_from_binary(nb_repeats * (NB_FRAMES_SEQ // 2), NB_CHECKS, stim_path, SETUP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20731e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Stimulus for Shifting White Noise\n",
    "MEA = 3 #int(input(\"\\nEnter MEA number 2 or 3 :\"))\n",
    "if MEA==2: \n",
    "    threshold  = 150e+3\n",
    "    pxl_size_dmd = 3.5\n",
    "    size_dmd = [864, 864]      # dimensions of the DMD, in pixels\n",
    "    polarity = 0\n",
    "if MEA==3:\n",
    "    threshold  = 170e+3   \n",
    "    size_dmd = [760, 1020]      # dimensions of the DMD, in pixels\n",
    "    pxl_size_dmd = 2.5          # The size of one pixel of the DMD in µm? on the camera or in reality?\n",
    "    polarity = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6df0f11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622c3c7bc6284c3594346c23c989a435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from binfile import *\n",
    "\n",
    "vec_file = \"/mnt/Extra/PulsatingGrating/20250907_BarcodeXPulsatingGrating/VEC_Files/20250512_4_SWN_48pixCh_6pixShift_30Hz_MEA3.vec\"\n",
    "bin_file = \"/mnt/Extra/PulsatingGrating/20250907_BarcodeXPulsatingGrating/VEC_Files/20250512_4_SWN_48pixCh_6pixShift_30Hz_MEA3.bin\"\n",
    "\n",
    "vec_trigs = np.loadtxt(vec_file)[1:]\n",
    "binObj = BinFile(bin_file, size_dmd[0], size_dmd[1], MEA, mode='r')\n",
    "\n",
    "shift_x_in_pix = 6\n",
    "shift_y_in_pix = 6\n",
    "checkerboard = []\n",
    "num_unrepeated_frames = vec_trigs.shape[0]//2  #Keeping only the random frames knowing half are repeated and random one idex start at 0\n",
    "\n",
    "for vec in tqdm(vec_trigs):\n",
    "    vec_index = int(vec[1])\n",
    "    if vec_index < num_unrepeated_frames:\n",
    "        checker = binObj.read_frame(vec_index)\n",
    "        checkerboard.append((checker[::shift_x_in_pix, ::shift_y_in_pix]/checker.max()))\n",
    "checkerboard = np.array(checkerboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b77bb756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a490c1d39d284208acc13b9851cec02e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parallel Analysis:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index 54000 is out of bounds for axis 0 with size 54000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/guiglaz/anaconda3/envs/spk/lib/python3.9/concurrent/futures/process.py\", line 246, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"/home/guiglaz/anaconda3/envs/spk/lib/python3.9/concurrent/futures/process.py\", line 205, in _process_chunk\n    return [fn(*args) for args in chunk]\n  File \"/home/guiglaz/anaconda3/envs/spk/lib/python3.9/concurrent/futures/process.py\", line 205, in <listcomp>\n    return [fn(*args) for args in chunk]\n  File \"/tmp/ipykernel_759254/2044722888.py\", line 112, in process_single_electrode\n    res_r = extract_from_sequence(spike_train, triggers, nb_repeats, stim_freq, nb_frames, (0.5, 1))\n  File \"/tmp/ipykernel_759254/2044722888.py\", line 11, in extract_from_sequence\n    t_ends = triggers[end_indices]\nIndexError: index 54000 is out of bounds for axis 0 with size 54000\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 3. Run in Parallel\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Adjust max_workers to the number of physical cores you want to use (e.g., 4, 8, or None for all)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m---> 22\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_single_electrode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mParallel Analysis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# 4. Convert list of tuples back to dictionary\u001b[39;00m\n\u001b[1;32m     27\u001b[0m processed_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(results)\n",
      "File \u001b[0;32m~/anaconda3/envs/spk/lib/python3.9/site-packages/tqdm/notebook.py:249\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/spk/lib/python3.9/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/spk/lib/python3.9/concurrent/futures/process.py:562\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[1;32m    557\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;124;03m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;124;03m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;124;03m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 562\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    563\u001b[0m         element\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    564\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m element:\n",
      "File \u001b[0;32m~/anaconda3/envs/spk/lib/python3.9/concurrent/futures/_base.py:609\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mresult(end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/anaconda3/envs/spk/lib/python3.9/concurrent/futures/_base.py:446\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/anaconda3/envs/spk/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 54000 is out of bounds for axis 0 with size 54000"
     ]
    }
   ],
   "source": [
    "# 1. Prepare shared parameters\n",
    "params = {\n",
    "    'nb_repeats': nb_repeats,\n",
    "    'stim_freq': STIM_FREQ,\n",
    "    'nb_frames': NB_FRAMES_SEQ,\n",
    "    'temp_dim': TEMPORAL_DIM,\n",
    "    'checkerboard': checkerboard # Note: Large arrays can be slow to pass between processes\n",
    "}\n",
    "\n",
    "# 2. Filter tasks\n",
    "tasks = [\n",
    "    (elec, mapping[elec], np.array(spike_trains_mua[elec]), triggers, params)\n",
    "    for elec in mapping.keys()\n",
    "    if elec not in [127, 128, 255, 256] and elec in spike_trains_mua\n",
    "]\n",
    "\n",
    "processed_data = {}\n",
    "\n",
    "# 3. Run in Parallel\n",
    "# Adjust max_workers to the number of physical cores you want to use (e.g., 4, 8, or None for all)\n",
    "with ProcessPoolExecutor(max_workers=10) as executor:\n",
    "    results = list(tqdm(executor.map(process_single_electrode, tasks), \n",
    "                        total=len(tasks), \n",
    "                        desc=\"Parallel Analysis\"))\n",
    "\n",
    "# 4. Convert list of tuples back to dictionary\n",
    "processed_data = dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "820d5963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dccd59293e144250a4c1cf527f1b40cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if PLOT_RASTER :\n",
    "    fig_r, axs_r = plt.subplots(16, 16, figsize=(15, 15))\n",
    "\n",
    "    for electrode, (row, col) in tqdm(mapping.items()):\n",
    "        ax_r = axs_r[row, col]\n",
    "\n",
    "        # Check if we have data for this electrode\n",
    "        if electrode not in processed_data:\n",
    "            ax_r.axis('off')\n",
    "            continue\n",
    "\n",
    "        data = processed_data[electrode]\n",
    "\n",
    "        # --- Plot Raster ---\n",
    "        ax_r.eventplot(data['raster_spikes'], linewidths=0.1, color='black')\n",
    "        ax_r.set_xticks([]); ax_r.set_yticks([])\n",
    "\n",
    "    plt.show(block = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a979f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba247cf34d3f405c9f282fd6b49feb79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Plotting Rasters:   0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if PLOT_RASTER:\n",
    "    # On utilise une résolution de DPI raisonnable pour ne pas ramer à l'affichage\n",
    "    fig_r, axs_r = plt.subplots(16, 16, figsize=(16, 16))\n",
    "    \n",
    "    data_dict = dict(processed_data) if isinstance(processed_data, list) else processed_data\n",
    "    \n",
    "    for electrode, (row, col) in tqdm(mapping.items(), desc=\"Plotting Rasters\"):\n",
    "        ax_r = axs_r[row, col]\n",
    "    \n",
    "        ax_r.set_xticks([])\n",
    "        ax_r.set_yticks([])\n",
    "        for spine in ax_r.spines.values():\n",
    "            spine.set_visible(False)\n",
    "    \n",
    "        if electrode not in data_dict:\n",
    "            # On laisse les électrodes vides en gris très clair pour voir la grille\n",
    "            ax_r.set_facecolor('#f9f9f9') \n",
    "            continue\n",
    "        data = data_dict[electrode]\n",
    "        ax_r.eventplot(data['raster_spikes'], \n",
    "                       linewidths=0.1, \n",
    "                       color='black', \n",
    "                       rasterized=True) \n",
    "    \n",
    "    \n",
    "    # 4. Ajustement manuel (beaucoup plus rapide que tight_layout)\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1, left=0.01, right=0.99, bottom=0.01, top=0.99)\n",
    "    \n",
    "    plt.show(block = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "455c55bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stitched_sta(processed_data, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86177b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected File : /home/guiglaz/Documents/MultiunitFromRaw/01_Checkerboard_30Hz_16px_40sq_30ND50%.raw\n",
      "Lecture triggers...\n",
      "Loading Trigger Channel: 100%|██████████████████| 75/75 [00:01<00:00, 53.08it/s]\n",
      "✅ Triggers OK (110462)                                                          \n",
      "Detected Stimulus Frequency: 30 Hz\n",
      "Number of repeats: 92\n",
      "Extraction des spikes...\n",
      "detect peaks using by_channel: 100%|████████| 3703/3703 [01:11<00:00, 51.96it/s]\n",
      "Chargement stimulus...\n",
      "Traitement des frames: 100%|██████████| 55200/55200 [00:00<00:00, 402962.94it/s]\n",
      "Parallel Analysis: 100%|██████████████████████| 252/252 [00:24<00:00, 10.09it/s]\n",
      "100%|█████████████████████████████████████████| 256/256 [00:12<00:00, 21.04it/s]\n",
      "Press any key to close...^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guiglaz/Documents/MultiunitFromRaw/STA_MU_Exec.py\", line 415, in <module>\n",
      "    input('Press any key to close...')\n",
      "KeyboardInterrupt\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python STA_MU_Exec.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
